{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e22ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset,DataLoader,Dataset,random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score,accuracy_score\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492c0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder=\"D:\\Jupyter Files\\Traffic Sign Recognition\\GTSRB_Final_Training_Images\\GTSRB\\Final_Training\\Images\"\n",
    "val_folder = 'D:/Jupyter Files/Traffic Sign Recognition/GTSRB_Final_Training_Images/GTSRB\\Final_Training' + '/val_images'\n",
    "if not os.path.isdir(val_folder):\n",
    "    print(val_folder + ' not found, making a validation set')\n",
    "    os.mkdir(val_folder)\n",
    "    for dirs in os.listdir(train_folder):\n",
    "        print(dirs)\n",
    "        if dirs.startswith('000'):\n",
    "            os.mkdir(val_folder + '/' + dirs)\n",
    "            for f in os.listdir(train_folder + '/' + dirs):\n",
    "                if f.startswith('00000') or f.startswith('00001') or f.startswith('00002'):\n",
    "                    # move file to validation folder\n",
    "                    os.rename(train_folder + '/' + dirs + '/' + f, val_folder + '/' + dirs + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acaf15e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(train_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf333c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = 43 # GTSRB as 43 classes\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 1, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(1, 29, kernel_size=5)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv3 = nn.Conv2d(29, 59, kernel_size=3)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv4 = nn.Conv2d(59, 74, kernel_size=3)\n",
    "        self.maxpool4 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(1184, 300)\n",
    "        self.fc2 = nn.Linear(300, nclasses)\n",
    "        self.conv0_bn = nn.BatchNorm2d(3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(29)\n",
    "        self.conv3_bn = nn.BatchNorm2d(59)\n",
    "        self.conv4_bn = nn.BatchNorm2d(74)\n",
    "        self.dense1_bn = nn.BatchNorm1d(300)\n",
    "    def forward(self, x):\n",
    "        x =  F.relu(self.conv1_bn(self.conv1(self.conv0_bn(x))))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3( self.maxpool2(x))))\n",
    "        x = F.relu(self.conv4_bn(self.conv4( self.maxpool3(x))))\n",
    "        x = self.maxpool4(x)        \n",
    "        x = x.view(-1, 1184)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dense1_bn(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14c79f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =50                                                                                                                                                                                     \n",
    "epochs = 10                                                                                                                                                                                                                                                                                                                                                                               \n",
    "seed = 1                                                                                                                                                                                           \n",
    "log_interval=180   \n",
    "nclasses = 43\n",
    "data = \"D:/Jupyter Files/Traffic Sign Recognition/GTSRB_Final_Training_Images/GTSRB\"                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "torch.manual_seed(1)                                                                                                                                                                               \n",
    "lr =0.007                                                                                                                                                                                          \n",
    "momentum = 0.9                                                                                                                                                                                     \n",
    "decay = 0.9                                                                                                                                                                                        \n",
    "step = 1000                                                                                                                                                                                        \n",
    "l2_norm = 0.00001  \n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fd36e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# once the images are loaded, how do we pre-process them before being passed into the network\n",
    "# by default, we resize the images to 48 x 48 in size\n",
    "# and normalize them to mean = 0 and standard-deviation = 1 based on statistics collected from\n",
    "# the training set\n",
    "data_transforms = transforms.Compose([\n",
    "#     transforms.ToPILImage(mode='RGB'),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(data + '/Final_Training/Images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(data + '/Final_Training/val_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = Net()\n",
    "if cuda: \n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6f7747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d13d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system?True\n",
      "CUDA version: 11.3\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system?{torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20721278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0+cu113'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98987649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sm_37',\n",
       " 'sm_50',\n",
       " 'sm_60',\n",
       " 'sm_61',\n",
       " 'sm_70',\n",
       " 'sm_75',\n",
       " 'sm_80',\n",
       " 'sm_86',\n",
       " 'compute_37']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_arch_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "010ce7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "751d6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    model.eval().to(device)\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        data =data.to(device)\n",
    "        target =target.to(device)\n",
    "        output = model(data)\n",
    "        validation_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return validation_loss\n",
    "\n",
    "def train(epoch , train_loader):\n",
    "    model.train().to(device)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target).cuda()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c379a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr , momentum=momentum, weight_decay=l2_norm, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96bbbd14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc3496a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ad60730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd39026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heril\\AppData\\Local\\Temp/ipykernel_22392/969698797.py:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/35339 (0%)]\tLoss: 1.543495\n",
      "Train Epoch: 1 [9000/35339 (25%)]\tLoss: 1.645278\n",
      "Train Epoch: 1 [18000/35339 (51%)]\tLoss: 1.774875\n",
      "Train Epoch: 1 [27000/35339 (76%)]\tLoss: 1.777056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heril\\AppData\\Local\\Temp/ipykernel_22392/3649215005.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.3988, Accuracy: 3618/3870 (93.488%)\n",
      "\n",
      "Train Epoch: 2 [0/35339 (0%)]\tLoss: 1.234313\n",
      "Train Epoch: 2 [9000/35339 (25%)]\tLoss: 1.537463\n",
      "Train Epoch: 2 [18000/35339 (51%)]\tLoss: 1.385032\n",
      "Train Epoch: 2 [27000/35339 (76%)]\tLoss: 2.046384\n",
      "\n",
      "Validation set: Average loss: 0.2937, Accuracy: 3687/3870 (95.271%)\n",
      "\n",
      "Train Epoch: 3 [0/35339 (0%)]\tLoss: 1.825904\n",
      "Train Epoch: 3 [9000/35339 (25%)]\tLoss: 1.782866\n",
      "Train Epoch: 3 [18000/35339 (51%)]\tLoss: 1.756194\n",
      "Train Epoch: 3 [27000/35339 (76%)]\tLoss: 1.916050\n",
      "\n",
      "Validation set: Average loss: 0.2802, Accuracy: 3707/3870 (95.788%)\n",
      "\n",
      "Train Epoch: 4 [0/35339 (0%)]\tLoss: 1.625724\n",
      "Train Epoch: 4 [9000/35339 (25%)]\tLoss: 1.454638\n",
      "Train Epoch: 4 [18000/35339 (51%)]\tLoss: 1.436962\n",
      "Train Epoch: 4 [27000/35339 (76%)]\tLoss: 1.683388\n",
      "\n",
      "Validation set: Average loss: 0.2824, Accuracy: 3723/3870 (96.202%)\n",
      "\n",
      "Train Epoch: 5 [0/35339 (0%)]\tLoss: 1.507162\n",
      "Train Epoch: 5 [9000/35339 (25%)]\tLoss: 1.396106\n",
      "Train Epoch: 5 [18000/35339 (51%)]\tLoss: 1.481049\n",
      "Train Epoch: 5 [27000/35339 (76%)]\tLoss: 1.726378\n",
      "\n",
      "Validation set: Average loss: 0.2860, Accuracy: 3712/3870 (95.917%)\n",
      "\n",
      "Train Epoch: 6 [0/35339 (0%)]\tLoss: 1.805421\n",
      "Train Epoch: 6 [9000/35339 (25%)]\tLoss: 1.560729\n",
      "Train Epoch: 6 [18000/35339 (51%)]\tLoss: 1.760770\n",
      "Train Epoch: 6 [27000/35339 (76%)]\tLoss: 1.391019\n",
      "\n",
      "Validation set: Average loss: 0.2676, Accuracy: 3711/3870 (95.891%)\n",
      "\n",
      "Train Epoch: 7 [0/35339 (0%)]\tLoss: 1.582648\n",
      "Train Epoch: 7 [9000/35339 (25%)]\tLoss: 1.708994\n",
      "Train Epoch: 7 [18000/35339 (51%)]\tLoss: 1.840389\n",
      "Train Epoch: 7 [27000/35339 (76%)]\tLoss: 1.622700\n",
      "\n",
      "Validation set: Average loss: 0.2180, Accuracy: 3755/3870 (97.028%)\n",
      "\n",
      "Train Epoch: 8 [0/35339 (0%)]\tLoss: 1.531786\n",
      "Train Epoch: 8 [9000/35339 (25%)]\tLoss: 1.915344\n",
      "Train Epoch: 8 [18000/35339 (51%)]\tLoss: 1.890935\n",
      "Train Epoch: 8 [27000/35339 (76%)]\tLoss: 1.750971\n",
      "\n",
      "Validation set: Average loss: 0.2125, Accuracy: 3756/3870 (97.054%)\n",
      "\n",
      "Train Epoch: 9 [0/35339 (0%)]\tLoss: 2.083681\n",
      "Train Epoch: 9 [9000/35339 (25%)]\tLoss: 1.448918\n",
      "Train Epoch: 9 [18000/35339 (51%)]\tLoss: 1.543360\n",
      "Train Epoch: 9 [27000/35339 (76%)]\tLoss: 1.567379\n",
      "\n",
      "Validation set: Average loss: 0.1703, Accuracy: 3774/3870 (97.519%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs):\n",
    "    train(epoch, train_loader)\n",
    "    val = validation()\n",
    "    if epoch % step :\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ff218cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model_' + str(epoch) + '.pth'\n",
    "torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcabe00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000.ppm</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.ppm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002.ppm</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003.ppm</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004.ppm</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename  ClassId\n",
       "0  00000.ppm       16\n",
       "1  00001.ppm        1\n",
       "2  00002.ppm       38\n",
       "3  00003.ppm       33\n",
       "4  00004.ppm       11"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv=pd.read_csv('D:/Jupyter Files/Traffic Sign Recognition/GTSRB_Final_Test_GT/GT-final_test.csv',sep=';')\n",
    "test_csv = test_csv[['Filename','ClassId']]\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e82fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateTestDataset(Dataset):\n",
    "    # the init method or the constructor method \n",
    "    def __init__(self,df_data,data_dir='../input/',transform=None):\n",
    "        \n",
    "        # the super() method dynamically represents the base class and super().__init__() calls the init method of base class \n",
    "        super().__init__()\n",
    "        self.df=df_data.values\n",
    "        self.data_dir=data_dir\n",
    "        self.transform=transform\n",
    "        \n",
    "    # gives the length when len(instance) is called\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    # getitem is used for extracting the instances attributes; generally used with lists , tuples\n",
    "    def __getitem__(self,index):\n",
    "        img_name,label=self.df[index]\n",
    "        img_path=os.path.join(self.data_dir,img_name)\n",
    "#         print(self.data_dir)\n",
    "#         print(img_path)\n",
    "        image=Image.open(img_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image=self.transform(image)\n",
    "            \n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8a263f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path=\"D:/Jupyter Files/Traffic Sign Recognition/GTSRB_Final_Test_Images/GTSRB\\Final_Test/Images\"\n",
    "test_dataset=CreateTestDataset(df_data=test_csv,data_dir=test_path,transform=data_transforms)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "322fd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = img.unsqueeze(0).to(device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "981333eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1 , Predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heril\\AppData\\Local\\Temp/ipykernel_22392/969698797.py:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label= test_dataset[100]\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "print('Label:',label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1ec06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_preds(dataset):\n",
    "    sum=0\n",
    "    labels=[]\n",
    "    preds=[]\n",
    "    for i in range(len(dataset)):\n",
    "        img,label=dataset[i]\n",
    "        x_test=predict_image(img,model)\n",
    "        labels.append(label)\n",
    "        preds.append(x_test)\n",
    "    return labels,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "689dcfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heril\\AppData\\Local\\Temp/ipykernel_22392/969698797.py:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9792\n",
      "Precision: 0.9795\n",
      "Recall: 0.9792\n",
      "F1 Score: 0.9789\n",
      "Cohen Kappa Score: 0.9784\n",
      "MCC: 0.9784\n",
      "\t\tClassification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        60\n",
      "           1       0.99      1.00      1.00       720\n",
      "           2       0.98      1.00      0.99       750\n",
      "           3       0.99      0.95      0.97       450\n",
      "           4       1.00      0.99      0.99       660\n",
      "           5       0.92      0.99      0.95       630\n",
      "           6       1.00      0.87      0.93       150\n",
      "           7       0.98      0.99      0.98       450\n",
      "           8       0.97      1.00      0.99       450\n",
      "           9       0.98      1.00      0.99       480\n",
      "          10       1.00      0.99      1.00       660\n",
      "          11       0.99      0.99      0.99       420\n",
      "          12       0.97      1.00      0.98       690\n",
      "          13       1.00      1.00      1.00       720\n",
      "          14       1.00      1.00      1.00       270\n",
      "          15       0.97      1.00      0.99       210\n",
      "          16       0.98      0.99      0.99       150\n",
      "          17       1.00      0.97      0.98       360\n",
      "          18       0.96      0.94      0.95       390\n",
      "          19       0.98      1.00      0.99        60\n",
      "          20       0.85      1.00      0.92        90\n",
      "          21       0.84      0.69      0.76        90\n",
      "          22       0.98      0.95      0.97       120\n",
      "          23       0.97      0.98      0.97       150\n",
      "          24       1.00      0.96      0.98        90\n",
      "          25       0.98      0.99      0.99       480\n",
      "          26       0.96      0.97      0.96       180\n",
      "          27       0.81      0.78      0.80        60\n",
      "          28       0.96      1.00      0.98       150\n",
      "          29       0.95      1.00      0.97        90\n",
      "          30       0.97      0.81      0.88       150\n",
      "          31       0.99      1.00      1.00       270\n",
      "          32       1.00      1.00      1.00        60\n",
      "          33       1.00      1.00      1.00       210\n",
      "          34       0.99      0.99      0.99       120\n",
      "          35       0.99      0.98      0.99       390\n",
      "          36       0.99      1.00      1.00       120\n",
      "          37       1.00      0.98      0.99        60\n",
      "          38       0.99      0.98      0.99       690\n",
      "          39       0.98      0.97      0.97        90\n",
      "          40       0.97      0.81      0.88        90\n",
      "          41       1.00      0.85      0.92        60\n",
      "          42       0.98      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.98     12630\n",
      "   macro avg       0.97      0.96      0.97     12630\n",
      "weighted avg       0.98      0.98      0.98     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_test,y_pred=get_labels_preds(test_dataset)\n",
    "print('Accuracy:', np.round(metrics.accuracy_score(y_test, y_pred),4))\n",
    "print('Precision:', np.round(metrics.precision_score(y_test, y_pred, average='weighted'),4))\n",
    "print('Recall:', np.round(metrics.recall_score(y_test,y_pred, average='weighted'),4))\n",
    "print('F1 Score:', np.round(metrics.f1_score(y_test, y_pred, average='weighted'),4))\n",
    "print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test, y_pred),4))\n",
    "print('MCC:', np.round(metrics.matthews_corrcoef(y_test, y_pred),4))\n",
    "print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
